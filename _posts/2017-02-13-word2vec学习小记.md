---
title: word2vec学习小记
date: 2017-02-13 14:39:39
tags: [word2vec, NLP, Google, 词向量, 入门, 教程, 实例, 自然语言处理]
categories: NLP
link_title: learning_word2vec
---
word2vec是Google于2013年开源推出的一个用于获取词向量的工具包，它简单、高效，因此引起了很多人的关注。最近项目组使用word2vec来实现个性化搜索，在阅读资料的过程中做了一些笔记，用于后面进一步学习。
<!-- more -->

## word2vec是什么？

> This tool provides an efficient implementation of the continuous bag-of-words and skip-gram architectures for computing vector representations of words. These representations can be subsequently used in many natural language processing applications and for further research.

从官方的介绍可以看出word2vec是一个将词表示为一个向量的工具，通过该向量表示，可以用来进行更深入的自然语言处理，比如机器翻译等。

## 基础知识
### 词向量表示
- 自然语言理解的问题要转化为机器学习的问题，第一步肯定是要找一种方法把这些符号数学化。
- 最直观的就是把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为0，只有一个维度的值为1，这个维度就代表了当前的词。这种表示方式被称为**One-hot Representation**。这种方式的优点在于简洁，但是却无法描述词与词之间的关系。
- 另外一种表示方法是通过一个低维的向量（通常为50维、100维或200维），其基于“**具有相似上下文的词，应该具有相似的语义**”的假说，这种表示方式被称为**Distributed Representation**。它是一个稠密、低维的实数向量，它的每一维表示词语的一个潜在特征，该特征捕获了有用的句法和语义特征。其特点是将词语的不同句法和语义特征分布到它的每一个维度上去表示。这种方式的好处是可以通过空间距离或者余弦夹角来描述词与词之间的相似性。

### 语言模型



### 神经网络概率语言模型



### word2vec的核心模型


## 通过实战了解word2vec
### 下载语料
从搜狗实验室下载[全网新闻数据(SogouCA)](http://www.sogou.com/labs/resource/ca.php)，该语料来自若干新闻站点2012年6月—7月期间国内、国际、体育、社会、娱乐等18个频道的新闻数据。

下载该文件解压后大约为1.5G，包含120w条以上的新闻，文件的内容格式如下图所示：

![搜狗CA语料内容格式](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/corpus_format.png)

### 获取新闻内容
这里我们先对语料进行初步处理，只获取新闻内容部分。可以执行以下命令获取content部分：

    cat news_tensite_xml.dat | iconv -f gbk -t utf-8 -c | grep "<content>"  > corpus.txt

### 分词处理
由于word2vec处理的数据是单词分隔的语句，对于中文来说，需要先进行分词处理。这里采用的是中国自然语言处理开源组织开源的[ansj_seg](https://github.com/NLPchina/ansj_seg)分词器，核心代码如下所示：

```java
public class WordAnalyzer {
    private static final String TAG_START_CONTENT = "<content>";
    private static final String TAG_END_CONTENT = "</content>";
    private static final String INPUT_FILE = "/home/test/w2v/corpus.txt";
    private static final String OUTPUT_FILE = "/home/test/w2v/corpus_out.txt";

    public static void main(String[] args) throws Exception {
        BufferedReader reader = null;
        PrintWriter pw = null;
        try {
            System.out.println("开始处理分词...");
            reader = IOUtil.getReader(INPUT_FILE, "UTF-8");
            pw = new PrintWriter(OUTPUT_FILE);
            long start = System.currentTimeMillis();
            int totalCharactorLength = 0;
            int totalTermCount = 0;
            Set<String> set = new HashSet<String>();
            String temp = null;
            while ((temp = reader.readLine()) != null) {
                temp = temp.trim();
                if (temp.startsWith(TAG_START_CONTENT)) {
                    //System.out.println("处理文本:" + temp);
                    int end = temp.indexOf(TAG_END_CONTENT);
                    String content = temp.substring(TAG_START_CONTENT.length(), end);
                    totalCharactorLength += content.length();
                    Result result = ToAnalysis.parse(content);
                    for (Term term : result) {
                        String item = term.getName().trim();
                        totalTermCount++;
                        pw.print(item + " ");
                        set.add(item);
                    }
                    pw.println();
                }
            }

            long end = System.currentTimeMillis();
            System.out.println("共" + totalTermCount + "个Term，共" 
                + set.size() + "个不同的Term，共 " 
                + totalCharactorLength + "个字符，每秒处理字符数:" 
                + (totalCharactorLength * 1000.0 / (end - start)));
        } finally {
            // close reader and pw
        }
    }
}
```

分词处理之后的文件内容如下所示：
![分词之后的语料](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/corpus_ansj_analyze.png)

### 下载word2vec源码并编译
这里我没有从官网下载而是从github上的[svn2github/word2vec](https://github.com/svn2github/word2vec)项目下载源码，下载之后执行make命令编译，这个过程很快就可以结束。

### 开始word2vec处理
编译成功后开始处理。我这里用的是CentOS 64位的虚拟机，八核CPU，32G内存，整个处理过程耗时大约4个小时。

    ./word2vec -train ../corpus_out.txt -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 12 -binary 1

### 测试处理结果
处理结束之后，使用distance命令可以测试处理结果，以下是分别测试【足球】和【改革】的效果：

![测试足球一词的词向量](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/w2v_test_football.png)

![测试改革一词的词向量](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/w2v_test_reform.png)


## 了解word2vec相关知识


## 学习小结


## 参考材料
- [word2vec HomePage](https://code.google.com/archive/p/word2vec/)
- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)
- [Deep Learning in NLP （一）词向量和语言模型](http://licstar.net/archives/328)
- [word2vec 中的数学原理详解](http://blog.csdn.net/itplus/article/details/37969635)
- [利用word2vec对关键词进行聚类](http://blog.csdn.net/zhaoxinfan/article/details/11069485)
- [word2vec词向量训练及中文文本相似度计算](http://blog.csdn.net/eastmount/article/details/50637476)
- [词表示模型（一）：表示学习；syntagmatic与paradigmatic两类模型；基于矩阵的LSA和GloVe](http://www.cnblogs.com/Determined22/p/5780305.html)
- [词表示模型（二）：基于神经网络的模型：NPLM；word2vec（CBOW/Skip-gram）](http://www.cnblogs.com/Determined22/p/5804455.html)
- [词表示模型（三）：word2vec（CBOW/Skip-gram）的加速：Hierarchical Softmax与Negative Sampling](http://www.cnblogs.com/Determined22/p/5807362.html)
- [Google 开源项目 word2vec 的分析？_杨超的回答](https://www.zhihu.com/question/21661274/answer/19331979)
- [Word2Vec-知其然知其所以然](https://www.zybuluo.com/Dounm/note/591752)
- [word2vec 原理篇](http://www.nustm.cn/blog/index.php/archives/842)