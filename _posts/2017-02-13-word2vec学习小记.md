---
title: word2vec学习小记
date: 2017-02-13 14:39:39
tags: [word2vec, NLP, Google, 词向量, 入门, 教程, 实例, 自然语言处理]
categories: NLP
link_title: learning_word2vec
---
word2vec是Google于2013年开源推出的一个用于获取词向量的工具包，它简单、高效，因此引起了很多人的关注。最近项目组使用word2vec来实现个性化搜索，在阅读资料的过程中做了一些笔记，用于后面进一步学习。
<!-- more -->

## word2vec是什么？


## 通过实战了解word2vec
### 下载语料
从搜狗实验室下载[全网新闻数据(SogouCA)](http://www.sogou.com/labs/resource/ca.php)，该语料来自若干新闻站点2012年6月—7月期间国内、国际、体育、社会、娱乐等18个频道的新闻数据。

下载该文件解压后大约为1.5G，包含120w条以上的新闻，文件的内容格式如下图所示：

![搜狗CA语料内容格式](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/corpus_format.png)

### 获取新闻内容
这里我们先对语料进行初步处理，只获取新闻内容部分。可以执行以下命令获取content部分：

    cat news_tensite_xml.dat | iconv -f gbk -t utf-8 -c | grep "<content>"  > corpus.txt

### 分词处理
由于word2vec处理的数据是单词分隔的语句，对于中文来说，需要先进行分词处理。这里采用的是中国自然语言处理开源组织开源的[ansj_seg](https://github.com/NLPchina/ansj_seg)分词器，核心代码如下所示：

```java
public class WordAnalyzer {
    private static final String TAG_START_CONTENT = "<content>";
    private static final String TAG_END_CONTENT = "</content>";
    private static final String INPUT_FILE = "/home/test/w2v/corpus.txt";
    private static final String OUTPUT_FILE = "/home/test/w2v/corpus_out.txt";

    public static void main(String[] args) throws Exception {
        BufferedReader reader = null;
        PrintWriter pw = null;
        try {
            System.out.println("开始处理分词...");
            reader = IOUtil.getReader(INPUT_FILE, "UTF-8");
            pw = new PrintWriter(OUTPUT_FILE);
            long start = System.currentTimeMillis();
            int totalCharactorLength = 0;
            int totalTermCount = 0;
            Set<String> set = new HashSet<String>();
            String temp = null;
            while ((temp = reader.readLine()) != null) {
                temp = temp.trim();
                if (temp.startsWith(TAG_START_CONTENT)) {
                    //System.out.println("处理文本:" + temp);
                    int end = temp.indexOf(TAG_END_CONTENT);
                    String content = temp.substring(TAG_START_CONTENT.length(), end);
                    totalCharactorLength += content.length();
                    Result result = ToAnalysis.parse(content);
                    for (Term term : result) {
                        String item = term.getName().trim();
                        totalTermCount++;
                        pw.print(item + " ");
                        set.add(item);
                    }
                    pw.println();
                }
            }

            long end = System.currentTimeMillis();
            System.out.println("共" + totalTermCount + "个Term，共" 
                + set.size() + "个不同的Term，共 " 
                + totalCharactorLength + "个字符，每秒处理字符数:" 
                + (totalCharactorLength * 1000.0 / (end - start)));
        } finally {
            // close reader and pw
        }
    }
}
```

分词处理之后的文件内容如下所示：
![分词之后的语料](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/corpus_ansj_analyze.png)

### 下载word2vec源码并编译
这里我没有从官网下载而是从github上的[svn2github/word2vec](https://github.com/svn2github/word2vec)项目下载源码，下载之后执行make命令编译，这个过程很快就可以结束。

### 开始word2vec处理
编译成功后开始处理。我这里用的是CentOS 64位的虚拟机，八核CPU，32G内存，整个处理过程耗时大约4个小时。

    ./word2vec -train ../corpus_out.txt -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 12 -binary 1

### 测试处理结果
处理结束之后，使用distance命令可以测试处理结果，以下是分别测试【足球】和【改革】的效果：

![测试足球一词的词向量](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/w2v_test_football.png)

![测试改革一词的词向量](http://oi46mo3on.bkt.clouddn.com/14_learning_w2v/w2v_test_reform.png)


## 了解word2vec相关知识


## 学习小结


## 参考材料
- [word2vec HomePage](https://code.google.com/archive/p/word2vec/)
- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)
- [利用word2vec对关键词进行聚类](http://blog.csdn.net/zhaoxinfan/article/details/11069485)

